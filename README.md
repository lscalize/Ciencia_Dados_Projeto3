# Projeto: Análise e Modelagem de Dados de Crédito e Censo com Machine Learning

# Análise e Modelagem de Dados de Crédito e Censo

Este projeto utiliza técnicas de análise e modelagem de dados para explorar duas bases de dados distintas: uma de crédito e outra do censo. O objetivo é preprocessar os dados, aplicar técnicas de visualização e preparar os dados para futuros modelos de machine learning.

## Estrutura do Projeto

1. **Exploração e Limpeza dos Dados de Crédito:**
   - Carregamento dos dados
   - Tratamento de valores inconsistentes
   - Tratamento de valores faltantes

2. **Exploração e Limpeza dos Dados do Censo:**
   - Carregamento dos dados
   - Tratamento de atributos categóricos com LabelEncoder e OneHotEncoder

3. **Modelagem e Preparação dos Dados:**
   - Separação entre variáveis previsoras e classe
   - Escalonamento dos atributos com StandardScaler

4. **Divisão em Treinamento e Teste:**
   - Divisão dos dados em conjuntos de treinamento e teste para ambas as bases

5. **Modelagem com Naive Bayes, Árvore de Decisão e Random Forest:**
   - Treinamento e avaliação dos modelos Naive Bayes, Árvore de Decisão e Random Forest

6. **Comparação de Resultados:**
   - Análise e comparação das métricas de desempenho dos modelos

## Resultados da Análise e Modelagem

### Base de Dados de Crédito

#### Naive Bayes
- **Acurácia:** 
- **Relatório de Classificação:**


#### Árvore de Decisão
- **Acurácia:** 
- **Relatório de Classificação:**


#### Random Forest
- **Acurácia:** 
- **Relatório de Classificação:**


### Base de Dados do Censo

#### Naive Bayes
- **Acurácia:** 
- **Relatório de Classificação:**


#### Árvore de Decisão
- **Acurácia:** 
- **Relatório de Classificação:**


#### Random Forest
- **Acurácia:** 
- **Relatório de Classificação:**



## Conclusão

Na base de dados de crédito, o modelo xxxxxxxxx apresentou a melhor acurácia...

Na base de dados do censo, o modelo yyyyyyy  teve um desempenho superior... 

O relatório de classificação indica que o Random Forest conseguiu capturar melhor as nuances dos dados.

Esses resultados destacam a importância de avaliar múltiplos modelos para entender qual se ajusta melhor aos dados específicos de cada caso.

## Como Executar

1. Clone o repositório.
2. Instale as dependências necessárias:
   ```sh
   pip install pandas numpy seaborn matplotlib plotly scikit-learn yellowbrick


Com essas adições, o código e o README.md estão prontos para serem usados diretamente no GitHub, com todos os detalhes necessários para replicar o projeto e entender os resultados.
